import 'package:flutter/material.dart';
import '../model/chat_message.dart';
import '../model/content_recommendation.dart';
import '../model/post_model.dart';
import '../services/gemini_service.dart';
import '../services/speech_service.dart';
import '../services/context_memory_service.dart';
import '../services/audio_spectrum_service.dart';
import '../services/rag_service.dart';

class ChatProvider with ChangeNotifier {
  final GeminiService _geminiService = GeminiService();
  final SpeechService _speechService = SpeechService();
  final ContextMemoryService _contextMemory = ContextMemoryService();
  final AudioSpectrumService _audioSpectrum = AudioSpectrumService();
  
  List<ChatMessage> _messages = [];
  bool _isListening = false;
  bool _isSpeaking = false;
  List<String> _conversationContext = [];

  // √âtat de suivi de la conversation
  String _currentTopic = '';
  bool _awaitingUserFeedback = false;

  List<ChatMessage> get messages => _messages;
  bool get isListening => _isListening;
  bool get isSpeaking => _isSpeaking;

  // Exposer les services
  GeminiService get geminiService => _geminiService;
  SpeechService get speechService => _speechService;
  ContextMemoryService get contextMemory => _contextMemory;
  AudioSpectrumService get audioSpectrum => _audioSpectrum;

  ChatProvider() {
    _initialize();
  }

  Future<void> _initialize() async {
    await _speechService.initialize();
    // Ajouter un message de bienvenue
    addMessage(ChatMessage(
      role: MessageRole.assistant,
      content: "Salut ! üòä Je suis Myla, ton assistante X Place. Comment puis-je t'aider √† d√©couvrir du super contenu aujourd'hui ?",
    ));
  }

  Future<void> sendMessage(String message) async {
    if (message.trim().isEmpty) return;

    // Ajouter le message √† la m√©moire contextuelle
    _contextMemory.addToShortTermMemory(message);
    _conversationContext.add("Utilisateur: $message");

    // Garder seulement les 10 derniers √©changes pour le contexte
    if (_conversationContext.length > 20) {
      _conversationContext = _conversationContext.sublist(_conversationContext.length - 20);
    }

    // Ajouter le message de l'utilisateur
    addMessage(ChatMessage(
      content: message,
      role: MessageRole.user,
    ));

    // Ajouter un message "en cours" pour l'assistant
    addMessage(ChatMessage(
      content: '',
      role: MessageRole.assistant,
      isProcessing: true,
    ));

    try {
      // Utiliser le syst√®me RAG pour g√©n√©rer la r√©ponse
      final ragResponse = await RAGService.generateRAGResponse(message, _conversationContext);
      
      // Supprimer le message de traitement
      _messages.removeWhere((msg) => msg.isProcessing);
      
      // Nettoyer et valider la r√©ponse
      String cleanResponse = ragResponse.text.trim();
      
      // S'assurer que la r√©ponse est compl√®te et naturelle
      if (cleanResponse.isEmpty) {
        cleanResponse = _generateContextualFallback(message);
      }
      
      // Ajouter la r√©ponse √† l'historique
      _conversationContext.add("Myla: $cleanResponse");
      
      // Ajouter la r√©ponse de l'assistant avec les posts recommand√©s
      addMessage(ChatMessage(
        content: cleanResponse,
        role: MessageRole.assistant,
        recommendedPosts: ragResponse.recommendedPosts,
      ));
      
      // Synth√®se vocale si activ√©e
      if (_speechService.isTtsEnabled) {
        _isSpeaking = true;
        _audioSpectrum.startAnalysis(isSpeaking: true);
        notifyListeners();
        
        try {
          await _speechService.speak(cleanResponse);
        } catch (e) {
          print("Erreur lors de la synth√®se vocale: $e");
        } finally {
          _isSpeaking = false;
          _audioSpectrum.stopAnalysis();
          notifyListeners();
        }
      }
      
    } catch (e) {
      print('Erreur lors de l\'envoi du message: $e');
      
      // Supprimer le message de traitement
      _messages.removeWhere((msg) => msg.isProcessing);
      
      // Message d'erreur avec fallback contextuel
      final fallbackMessage = _generateContextualFallback(message);
      addMessage(ChatMessage(
        content: fallbackMessage,
        role: MessageRole.assistant,
      ));
    }

    notifyListeners();
  }

  // G√©n√©ration de r√©ponses de fallback contextuelles
  String _generateContextualFallback(String userMessage) {
    final messageLower = userMessage.toLowerCase();
    
    if (messageLower.contains('salut') || messageLower.contains('bonjour') || messageLower.contains('hello')) {
      return "Salut ! üòä Je suis Myla, ton assistante sur X Place ! Comment √ßa va ? Tu cherches quelque chose en particulier ?";
    } else if (messageLower.contains('aide') || messageLower.contains('help')) {
      return "Bien s√ªr, je suis l√† pour t'aider ! Tu peux me demander du contenu par type, chercher des posts sp√©cifiques, ou juste explorer ce qu'on a de cool sur X Place ! üé¨";
    } else if (messageLower.contains('merci')) {
      return "De rien ! üòä C'est toujours un plaisir de t'aider ! Tu veux d√©couvrir autre chose ?";
    } else if (messageLower.contains('vid√©o') || messageLower.contains('contenu') || messageLower.contains('post')) {
      return "Super ! On a plein de contenu g√©nial sur X Place ! Tu cherches quelque chose en particulier ? Vid√©os, images, posts premium... ? üé•";
    } else {
      return "Hmm, je vois que tu t'int√©resses √† √ßa ! Dis-moi plus pr√©cis√©ment ce que tu aimerais voir et je vais te trouver le contenu parfait sur X Place ! ‚ú®";
    }
  }

  void addMessage(ChatMessage message) {
    _messages.add(message);
    notifyListeners();
  }

  void clearChat() {
    _messages.clear();
    _conversationContext.clear();
    _contextMemory.clearShortTermMemory();
    notifyListeners();
  }

  Future<void> startListening() async {
    if (_isListening) return;
    
    _isListening = true;
    // D√©marrer l'analyse du spectre en mode √©coute
    _audioSpectrum.startAnalysis(isSpeaking: false);
    notifyListeners();
    
    // Ajouter un message utilisateur vide qui sera mis √† jour en temps r√©el
    _messages.add(ChatMessage(
      content: "",
      role: MessageRole.user,
      isProcessing: true,
    ));
    notifyListeners();
    
    try {
      print('üéØ D√©marrage de l\'√©coute avec arr√™t automatique intelligent');
      
      await _speechService.startListening((recognizedText) {
        // V√©rifier si c'est un message de finalisation automatique
        if (recognizedText.startsWith("__FINALIZE__:")) {
          final finalText = recognizedText.substring("__FINALIZE__:".length);
          print('üèÅ Finalisation automatique d√©tect√©e: "$finalText"');
          _finalizeAutomatically(finalText);
          return;
        }
        
        // Mise √† jour du message en temps r√©el si on est encore en √©coute
        if (_isListening && _messages.isNotEmpty) {
          final lastMessage = _messages.last;
          if (lastMessage.role == MessageRole.user && lastMessage.isProcessing) {
            // Mettre √† jour le contenu du message sans cr√©er un nouveau message
            _messages[_messages.length - 1] = ChatMessage(
              content: recognizedText,
              role: MessageRole.user,
              isProcessing: true,
            );
            notifyListeners();
            
            print('üìù Mise √† jour en temps r√©el: "$recognizedText"');
          }
        }
      });
    } catch (e) {
      print('‚ùå Erreur lors de l\'√©coute: $e');
      _isListening = false;
      _audioSpectrum.stopAnalysis();
      
      // Supprimer le message en cours si erreur
      if (_messages.isNotEmpty && _messages.last.isProcessing) {
        _messages.removeLast();
      }
      
      notifyListeners();
    }
  }

  // Nouvelle m√©thode pour la finalisation automatique
  void _finalizeAutomatically(String finalText) async {
    if (!_isListening) return;
    
    print('ü§ñ Finalisation automatique du message: "$finalText"');
    
    _isListening = false;
    _audioSpectrum.stopAnalysis();
    
    // Finaliser le message utilisateur et l'envoyer au bot
    if (_messages.isNotEmpty && 
        _messages.last.role == MessageRole.user && 
        _messages.last.isProcessing) {
      
      _messages.removeLast();
      
      if (finalText.isNotEmpty && finalText.length > 1) {
        print('üì® Message finalis√© automatiquement et envoy√©: "$finalText"');
        
        // Ajouter le message finalis√© de l'utilisateur
        addMessage(ChatMessage(
          content: finalText,
          role: MessageRole.user,
        ));
        
        // Traiter le message avec le syst√®me RAG
        _processUserMessage(finalText);
      } else {
        print('‚ö†Ô∏è Message trop court ignor√©: "$finalText"');
      }
    }
    
    notifyListeners();
  }

  // V√©rifier si le texte semble complet (gard√© pour compatibilit√© mais moins utilis√©)
  bool _isTextComplete(String text) {
    if (text.trim().isEmpty) return false;
    
    // V√©rifier la ponctuation de fin
    final endsWithPunctuation = text.trim().endsWith('.') || 
                               text.trim().endsWith('!') || 
                               text.trim().endsWith('?');
    
    // V√©rifier la longueur (au moins 3 mots)
    final hasMinimumWords = text.trim().split(' ').length >= 3;
    
    // Mots-cl√©s de fin de phrase
    final endWords = ['merci', 'voil√†', 'c\'est tout', 'fini', 'termin√©'];
    final endsWithEndWord = endWords.any((word) => text.toLowerCase().trim().endsWith(word));
    
    return (endsWithPunctuation && hasMinimumWords) || 
           (endsWithEndWord && hasMinimumWords) ||
           (hasMinimumWords && text.length > 20);
  }

  // Finaliser l'√©coute manuellement (pour le bouton stop)
  void _finalizeListening() async {
    if (!_isListening) return;
    
    try {
      await _speechService.stopListening();
    } catch (e) {
      print("Erreur stopListening: $e");
    }
    
    _isListening = false;
    _audioSpectrum.stopAnalysis();
    
    // Finaliser le message utilisateur et l'envoyer au bot
    if (_messages.isNotEmpty && 
        _messages.last.role == MessageRole.user && 
        _messages.last.isProcessing) {
      
      String userMessage = _messages.last.content.trim();
      _messages.removeLast();
      
      if (userMessage.isNotEmpty && userMessage.length > 1) {
        print('üì® Message finalis√© manuellement et envoy√©: "$userMessage"');
        
        // Ajouter le message finalis√© de l'utilisateur
        addMessage(ChatMessage(
          content: userMessage,
          role: MessageRole.user,
        ));
        
        // Traiter le message avec le syst√®me RAG
        _processUserMessage(userMessage);
      } else {
        print('‚ö†Ô∏è Message trop court ignor√©: "$userMessage"');
      }
    }
    
    notifyListeners();
  }

  Future<void> stopListening() async {
    if (!_isListening) return;
    
    print('üõë Arr√™t manuel de l\'√©coute par l\'utilisateur');
    _finalizeListening();
  }

  Future<void> stopSpeaking() async {
    if (!_isSpeaking) return;
    
    await _speechService.stopSpeaking();
    _isSpeaking = false;
    _audioSpectrum.stopAnalysis();
    notifyListeners();
  }

  // Ajouter une m√©thode pour les suggestions contextuelles
  List<String> getContextualSuggestions() {
    return [
      "Contenu populaire",
      "Vid√©os r√©centes", 
      "Posts premium",
      "Contenu gratuit",
      "Nouveaut√©s",
      "Featured"
    ];
  }

  // Traiter le message utilisateur avec le syst√®me RAG
  Future<void> _processUserMessage(String message) async {
    // Ajouter un message "en cours" pour l'assistant
    addMessage(ChatMessage(
      content: '',
      role: MessageRole.assistant,
      isProcessing: true,
    ));

    try {
      // Utiliser le syst√®me RAG pour g√©n√©rer la r√©ponse
      final ragResponse = await RAGService.generateRAGResponse(message, _conversationContext);
      
      // Supprimer le message de traitement
      _messages.removeWhere((msg) => msg.isProcessing);
      
      // Nettoyer et valider la r√©ponse
      String cleanResponse = ragResponse.text.trim();
      
      if (cleanResponse.isEmpty) {
        cleanResponse = _generateContextualFallback(message);
      }
      
      // Ajouter la r√©ponse √† l'historique
      _conversationContext.add("Myla: $cleanResponse");
      
      // Ajouter la r√©ponse de l'assistant avec les posts recommand√©s
      addMessage(ChatMessage(
        content: cleanResponse,
        role: MessageRole.assistant,
        recommendedPosts: ragResponse.recommendedPosts,
      ));
      
      // Synth√®se vocale si activ√©e
      if (_speechService.isTtsEnabled) {
        _isSpeaking = true;
        _audioSpectrum.startAnalysis(isSpeaking: true);
        notifyListeners();
        
        try {
          await _speechService.speak(cleanResponse);
        } catch (e) {
          print("Erreur lors de la synth√®se vocale: $e");
        } finally {
          _isSpeaking = false;
          _audioSpectrum.stopAnalysis();
          notifyListeners();
        }
      }
      
    } catch (e) {
      print('Erreur lors du traitement du message: $e');
      
      // Supprimer le message de traitement
      _messages.removeWhere((msg) => msg.isProcessing);
      
      // Message d'erreur
      addMessage(ChatMessage(
        content: _generateContextualFallback(message),
        role: MessageRole.assistant,
      ));
    }

    notifyListeners();
  }

  @override
  void dispose() {
    _isListening = false;
    _isSpeaking = false;
    _audioSpectrum.stopAnalysis();
    super.dispose();
  }
}
